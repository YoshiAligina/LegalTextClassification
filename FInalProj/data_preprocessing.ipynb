{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  case_id case_outcome                                         case_title  \\\n",
      "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
      "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
      "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
      "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
      "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
      "\n",
      "                                           case_text  \n",
      "0  Ordinarily that discretion will be exercised s...  \n",
      "1  The general principles governing the exercise ...  \n",
      "2  Ordinarily that discretion will be exercised s...  \n",
      "3  The general principles governing the exercise ...  \n",
      "4  The preceding general principles inform the ex...  \n",
      "Columns in the dataset: Index(['case_id', 'case_outcome', 'case_title', 'case_text'], dtype='object')\n",
      "case_id           0\n",
      "case_outcome      0\n",
      "case_title        0\n",
      "case_text       176\n",
      "dtype: int64\n",
      "case_outcome\n",
      "cited            12219\n",
      "referred to       4384\n",
      "applied           2448\n",
      "followed          2256\n",
      "considered        1712\n",
      "discussed         1024\n",
      "distinguished      608\n",
      "related            113\n",
      "affirmed           113\n",
      "approved           108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\yoshi\\OneDrive\\Desktop\\CSMaster\\CS439\\FInalProj\\legalData\\legal_text_classification.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Print the column names to verify\n",
    "print(\"Columns in the dataset:\", df.columns)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check the distribution of case outcomes\n",
    "if 'case_outcome' in df.columns:\n",
    "    print(df['case_outcome'].value_counts())\n",
    "else:\n",
    "    print(\"The 'case_outcome' column is not present in the dataset.\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           case_text  \\\n",
      "0  Ordinarily that discretion will be exercised s...   \n",
      "1  The general principles governing the exercise ...   \n",
      "2  Ordinarily that discretion will be exercised s...   \n",
      "3  The general principles governing the exercise ...   \n",
      "4  The preceding general principles inform the ex...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  ordinarily discretion exercised cost follow ev...  \n",
      "1  general principle governing exercise discretio...  \n",
      "2  ordinarily discretion exercised cost follow ev...  \n",
      "3  general principle governing exercise discretio...  \n",
      "4  preceding general principle inform exercise di...  \n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply preprocessing to the case_text column\n",
    "df['cleaned_text'] = df['case_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned text\n",
    "print(df[['case_text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text case_category\n",
      "0  ordinarily discretion exercised cost follow ev...         other\n",
      "1  general principle governing exercise discretio...         other\n",
      "2  ordinarily discretion exercised cost follow ev...         other\n",
      "3  general principle governing exercise discretio...         other\n",
      "4  preceding general principle inform exercise di...         other\n",
      "Sorted dataset saved to legalData/sorted_legal_text.csv\n"
     ]
    }
   ],
   "source": [
    "keywords = {\n",
    "    'family': [\n",
    "        'children', 'custody', 'divorce', 'marriage', 'adoption', \n",
    "        'parenting orders', 'child support', 'spousal maintenance',\n",
    "        'family violence', 'guardianship', 'prenuptial agreements'\n",
    "    ],\n",
    "    'property': [\n",
    "        'property', 'ownership', 'land', 'real estate', 'lease',\n",
    "        'easements', 'mortgages', 'foreclosure', 'zoning',\n",
    "        'landlord', 'tenant', 'eviction'\n",
    "    ],\n",
    "    'criminal': [\n",
    "        'theft', 'murder', 'assault', 'fraud', 'crime',\n",
    "        'sentencing', 'bail', 'parole', 'prosecution',\n",
    "        'homicide', 'robbery', 'drug offenses'\n",
    "    ],\n",
    "    'business': [\n",
    "        'contract', 'agreement', 'corporation', \n",
    "        'partnership', 'mergers', 'franchises',\n",
    "        'intellectual property', 'trade practices'\n",
    "    ],\n",
    "    'financial_and_securities': [\n",
    "        'securities', 'investments', \n",
    "        'insider trading', \n",
    "        'market manipulation',\n",
    "        'financial services'\n",
    "    ],\n",
    "    'administrative': [\n",
    "        \"judicial review\", \"government decisions\", \"statutory interpretation\"\n",
    "    ],\n",
    "    \"employment\": [\"workers comp\"]\n",
    "}\n",
    "\n",
    "def assign_category(text):\n",
    "    for category, words in keywords.items():\n",
    "        if any(word in text.lower() for word in words):\n",
    "            return category\n",
    "    return 'other'  # Default category if no keywords match\n",
    "\n",
    "# Apply the function to the cleaned text column\n",
    "df['case_category'] = df['cleaned_text'].apply(assign_category)\n",
    "\n",
    "# Display the sorted dataset\n",
    "print(df[['cleaned_text', 'case_category']].head())\n",
    "\n",
    "# Save the sorted dataset to a CSV file\n",
    "output_file = 'legalData/sorted_legal_text.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sorted dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text saved to legalData\\cleaned_legal_text.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'legalData'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned text to a CSV file\n",
    "output_file = os.path.join(output_dir, 'cleaned_legal_text.csv')\n",
    "df[['case_text', 'cleaned_text']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned text saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8601160696417851\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          administrative       0.92      0.57      0.70       120\n",
      "                business       0.87      0.75      0.81       800\n",
      "                criminal       0.88      0.59      0.70       219\n",
      "                  family       0.99      0.53      0.69       143\n",
      "financial_and_securities       0.00      0.00      0.00         1\n",
      "                   other       0.85      0.97      0.91      2604\n",
      "                property       0.86      0.81      0.83      1110\n",
      "\n",
      "                accuracy                           0.86      4997\n",
      "               macro avg       0.77      0.60      0.66      4997\n",
      "            weighted avg       0.86      0.86      0.85      4997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yoshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yoshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yoshi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['cleaned_text'], df['case_category'], test_size=0.2, random_state=777\n",
    ")\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization, scaling, and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),  # Convert text to numerical features\n",
    "    ('scaler', MaxAbsScaler()),                     # Scale the features\n",
    "    ('logistic', LogisticRegression(max_iter=500, solver='liblinear', C=1.0, penalty='l2'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legal_text_classification_model.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the pipeline (model) and vectorizer\n",
    "joblib.dump(pipeline, 'legal_text_classification_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the pre-trained model and TF-IDF vectorizer\n",
    "model = joblib.load('legal_text_classification_model.pkl')\n",
    "tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Define a function to predict the category of a legal document\n",
    "def predict_category(text):\n",
    "    # Preprocess the input text\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    \n",
    "    # Transform the text using the TF-IDF vectorizer\n",
    "    text_tfidf = tfidf.transform([cleaned_text])\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(text_tfidf)\n",
    "    \n",
    "    return prediction[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
